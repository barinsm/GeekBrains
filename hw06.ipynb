{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ к Урок 6. Рекуррентные нейронные сети. LSTM. GRU.\n",
    "Провести сравнение RNN, LSTM, GRU на датасете отзывов (из предыдущих занятий/материалов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем запрограммировать простую рекурентную сеть. Возьмем датасет с прошлого занятия\n",
    "\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_val = pd.read_csv(\"data/val.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
    "df_test['text'] = df_test['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus_train = df_train['text'].values\n",
    "text_corpus_valid = df_val['text'].values\n",
    "text_corpus_test = df_test['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, \n",
    "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, split = ' ')\n",
    "tokenizer.fit_on_texts(text_corpus_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
    "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
    "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
    "\n",
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in text_corpus_train])\n",
    "\n",
    "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
    "X_valid = pad_sequences(sequences_val, maxlen=training_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['class'].values\n",
    "y_val = df_val['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kinetik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/kinetik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kinetik/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 163320 samples, validate on 18147 samples\n",
      "Epoch 1/10\n",
      "163320/163320 [==============================] - 47s 286us/step - loss: 0.5615 - accuracy: 0.6979 - val_loss: 0.4914 - val_accuracy: 0.7561\n",
      "Epoch 2/10\n",
      "163320/163320 [==============================] - 38s 235us/step - loss: 0.2863 - accuracy: 0.8832 - val_loss: 0.5659 - val_accuracy: 0.7419\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22683/22683 [==============================] - 1s 30us/step\n",
      "\n",
      "\n",
      "Test score: 0.5922189054836836\n",
      "Test accuracy: 0.7285191416740417\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 163320 samples, validate on 18147 samples\n",
      "Epoch 1/10\n",
      "163320/163320 [==============================] - 76s 463us/step - loss: 0.5553 - accuracy: 0.7066 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 2/10\n",
      "163320/163320 [==============================] - 55s 339us/step - loss: 0.3275 - accuracy: 0.8637 - val_loss: 0.5323 - val_accuracy: 0.7484\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22683/22683 [==============================] - 1s 63us/step\n",
      "\n",
      "\n",
      "Test score: 0.5562064222430119\n",
      "Test accuracy: 0.7420535087585449\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 163320 samples, validate on 18147 samples\n",
      "Epoch 1/10\n",
      "163320/163320 [==============================] - 68s 413us/step - loss: 0.5526 - accuracy: 0.7081 - val_loss: 0.5137 - val_accuracy: 0.7395\n",
      "Epoch 2/10\n",
      "163320/163320 [==============================] - 53s 322us/step - loss: 0.3153 - accuracy: 0.8705 - val_loss: 0.5307 - val_accuracy: 0.7405\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(GRU(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22683/22683 [==============================] - 2s 71us/step\n",
      "\n",
      "\n",
      "Test score: 0.5643668973440111\n",
      "Test accuracy: 0.7323546409606934\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
