{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Урок 8. Обучение с учителем в Scikit-learn. Видеоурок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируйте библиотеки pandas и numpy.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "feature_names = boston.feature_names\n",
    "X = pd.DataFrame(data, columns=feature_names)\n",
    "y = pd.DataFrame(target, columns=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки \n",
    "# составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711226005748496"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics.\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "# Сделайте агрумент n_estimators равным 1000, \n",
    "# max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(max_depth = 12, n_estimators = 1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=12,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, \n",
    "# но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "# чтобы получить из датафрейма одномерный массив Numpy,\n",
    "# так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "model.fit(X_train, y_train.values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8749965273218174"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "y_pred = model.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n",
    "\n",
    "# Модель RandomForestRegressor работает лучше чем модель LinearRegression, так как имеет большую метрику R2 (ближе к 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999994"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вызовите документацию для класса RandomForestRegressor,\n",
    "# найдите информацию об атрибуте feature_importances_.\n",
    "# С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "model.feature_importances_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03211748, 0.00154999, 0.0070941 , 0.0011488 , 0.01436832,\n",
       "       0.40270459, 0.01424477, 0.06403265, 0.00496762, 0.01169177,\n",
       "       0.01808961, 0.0123114 , 0.41567892])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# установите, какие два признака показывают наибольшую важность.\n",
    "model.feature_importances_\n",
    "# Наибольшую важность показывают признаки с индексами массива 5 (0.40270459) и 12 (0.41567892) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RM', 'LSTAT')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Это следующие признаки\n",
    "feature_names[5], feature_names[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Задание 4\n",
    "# В этом задании мы будем работать с датасетом, с которым мы уже \n",
    "# знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.\n",
    "# Для этого датасета мы будем решать задачу классификации - будем определять, \n",
    "# какие из транзакциции по кредитной карте являются мошенническими.\n",
    "# Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),\n",
    "# так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.\n",
    "# Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "\n",
    "# Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "\n",
    "# Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "\n",
    "# С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.\n",
    "\n",
    "# Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.\n",
    "\n",
    "# Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "# pd.options.display.max_columns = 100.\n",
    "\n",
    "# Просмотрите первые 10 строк датафрейма df.\n",
    "\n",
    "# Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "\n",
    "# Создайте объект Series под названием y из столбца Class.\n",
    "\n",
    "# Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "# У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "# Просмотрите информацию о их форме.\n",
    "\n",
    "# Для поиска по сетке параметров задайте такие параметры:\n",
    "# parameters = [{'n_estimators': [10, 15], \n",
    "# 'max_features': np.arange(3, 5),\n",
    "# 'max_depth': np.arange(4, 7)}]\n",
    "\n",
    "# Создайте модель GridSearchCV со следующими аргументами:\n",
    "# estimator=RandomForestClassifier(random_state=100), \n",
    "# param_grid=parameters,\n",
    "# scoring='roc_auc',\n",
    "# cv=3.\n",
    "\n",
    "# Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "\n",
    "# Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "\n",
    "# Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "# Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba.\n",
    "\n",
    "# Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "\n",
    "# Вычислите AUC на тестовых данных и сравните с результатом, \n",
    "# полученным на тренировочных данных, используя в качестве аргументов\n",
    "# массивы y_test и y_pred_proba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Дополнительные задания:\n",
    "\n",
    "# 1). Загрузите датасет Wine из встроенных датасетов sklearn.datasets с помощью функции load_wine в переменную data.\n",
    "\n",
    "# 2). Полученный датасет не является датафреймом. Это структура данных, имеющая ключи аналогично словарю. Просмотрите тип данных этой структуры данных и создайте список data_keys, содержащий ее ключи.\n",
    "\n",
    "# 3). Просмотрите данные, описание и названия признаков в датасете. Описание нужно вывести в виде привычного, аккуратно оформленного текста, без обозначений переноса строки, но с самими переносами и т.д.\n",
    "\n",
    "# 4). Сколько классов содержит целевая переменная датасета? Выведите названия классов.\n",
    "\n",
    "# 5). На основе данных датасета (они содержатся в двумерном массиве Numpy) и названий признаков создайте датафрейм под названием X.\n",
    "\n",
    "# 6). Выясните размер датафрейма X и установите, имеются ли в нем пропущенные значения.\n",
    "\n",
    "# 7). Добавьте в датафрейм поле с классами вин в виде чисел, имеющих тип данных numpy.int64. Название поля - 'target'.\n",
    "\n",
    "# 8). Постройте матрицу корреляций для всех полей X. Дайте полученному датафрейму название X_corr.\n",
    "\n",
    "# 9). Создайте список high_corr из признаков, корреляция которых с полем target по абсолютному значению превышает 0.5 (причем, само поле target не должно входить в этот список).\n",
    "\n",
    "# 10). Удалите из датафрейма X поле с целевой переменной. Для всех признаков, названия которых содержатся в списке high_corr, вычислите квадрат их значений и добавьте в датафрейм X соответствующие поля с суффиксом '_2', добавленного к первоначальному названию признака. Итоговый датафрейм должен содержать все поля, которые, были в нем изначально, а также поля с признаками из списка high_corr, возведенными в квадрат. Выведите описание полей датафрейма X с помощью метода describe.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
