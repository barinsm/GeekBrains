{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДЗ к Урок 3. Generative adversarial networks (GAN): генеративные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключаем нужные модули и библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "########### Вывод изображений и сохранение ################################\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from torchvision.utils import save_image, make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%time is a cell magic, but the cell body is empty. Did you mean the line magic %time (single %)?\n"
     ]
    }
   ],
   "source": [
    "%%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## функция для вывода и сохранения изображения ########\n",
    "def sample_image(static_sample, save_img = False):\n",
    "    npimg = make_grid(static_sample.data[:25]).cpu().numpy()\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax.imshow(np.transpose(npimg, (1,2,0)), interpolation=\"nearest\")\n",
    "    if save_img:\n",
    "        save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Домашнее задание: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Как было сказано ранее, GAN обучается воспроизводить реальные данные. Поэтому Вам предлагается обучить генератор создавать точки, которые будут лежать на графике функции $y = \\frac{sin(x)}{x} - \\frac{x}{10}$. При выполненинии данного задания структура GAN остается той же, но Вам нужно:\n",
    " * Сгенерировать настоящие данные\n",
    " * Изменить архитектуру дискриминатора и генератора\n",
    " * Без графиков домашку не принимаю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func_y: [ 0.74147098 -3.03293439]\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(1,30,2)\n",
    "def func_y(x):\n",
    "    return np.sin(x)/x - x/10\n",
    "print(\"Func_y:\", func_y(x))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Изменить используемые модели генератора и дискриминатора, с помощью сверточных слоев. Идея: https://arxiv.org/abs/1511.06434 Датасет можно использовать так же MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры для обучения обеих моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "latent_dim = 100\n",
    "\n",
    "n_classes = 10\n",
    "img_size = 28\n",
    "channels = 1\n",
    "\n",
    "sample_interval = 25\n",
    "\n",
    "img_shape = (channels, img_size, img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize=True): #activation='relu\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "#         self.activations = nn.ModuleDict([\n",
    "#                 ['lrelu', nn.LeakyReLU()],\n",
    "#                 ['relu', nn.ReLU()]])\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание своих слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinearLayer(nn.Module):\n",
    "    def __init__(self, size_in, size_out):\n",
    "        super().__init__()\n",
    "        self.size_in, self.size_out = size_in, size_out\n",
    "        \n",
    "        weights = torch.Tensor(size_out, size_in)\n",
    "        self.weights = nn.Parameter(weights) \n",
    "\n",
    "        bias = torch.Tensor(size_out)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "\n",
    "        nn.init.uniform_(self.weights, -0.005, 0.005) \n",
    "        nn.init.uniform_(self.bias, -0.005, 0.005)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        w_times_x = torch.mm(x, self.weights.t())\n",
    "        return torch.add(w_times_x, self.bias)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дискриминатор "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            CustomLinearLayer(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            CustomLinearLayer(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            CustomLinearLayer(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "  \n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "real_data = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../../data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f15021d6d8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(real_data)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "img = np.squeeze(images[0])\n",
    "img1 = np.squeeze(images[1])\n",
    "img2 = np.squeeze(images[2])\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (12,4))\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.imshow(img1, cmap='gray')\n",
    "ax3.imshow(img2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_history = []\n",
    "g_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 197/200] [Batch 89/938] [D loss: 0.381963] [G loss: 1.430800]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "red_patch = mpatches.Patch(color='red', label='D loss')\n",
    "green_patch = mpatches.Patch(color='green', label='G loss')\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(real_data):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "##################### Лейблы для данных: 1 - настоящие, 0 - сгенерированные ########\n",
    "        valid = Variable(torch.FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False).to(device)\n",
    "        fake = Variable(torch.FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False).to(device)\n",
    "\n",
    "        real_imgs = Variable(imgs.type(torch.FloatTensor)).to(device)\n",
    "\n",
    "\n",
    "######################  Тренировка генератора    ##########################\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "    \n",
    "        #генерация шума\n",
    "        z = Variable(torch.FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim)))).to(device)\n",
    "\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        validity = discriminator(gen_imgs)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "######################  Тренировка дискриминатора    ##########################\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_pred = discriminator(real_imgs)\n",
    "        d_real_loss = adversarial_loss(real_pred, valid)\n",
    "\n",
    "        fake_pred = discriminator(gen_imgs.detach())\n",
    "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
    "\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "######## Отображение процесса обучения и вывод функций потерь ############\n",
    "        batches_done = epoch * len(real_data) + i\n",
    "    \n",
    "        if batches_done % sample_interval == 0:\n",
    "            plt.clf()\n",
    "            \n",
    "            display.clear_output(wait=False)\n",
    "            sample_image(gen_imgs)\n",
    "            print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"% (epoch, n_epochs, i, len(real_data), d_loss.item(), g_loss.item()) ) \n",
    "\n",
    "            \n",
    "            display.display(plt.gcf())\n",
    "\n",
    "#             d_loss_history.append(d_loss)\n",
    "#             g_loss_history.append(g_loss)\n",
    "\n",
    "#             plt.plot(np.log(np.array(d_loss_history)), label='D loss', color = 'red')\n",
    "#             plt.plot(np.log(np.array(g_loss_history)), label='G loss', color = 'green')\n",
    "#             plt.legend(handles=[red_patch, green_patch])\n",
    "#             plt.show()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), \"vanilla_gan.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
